{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"DeSi Documentation","text":"<p>DeSi (DataStore Helper) is a retrieval-augmented chatbot that answers questions about openBIS and BAM Data Store documentation. It scrapes docs, processes them into embeddings with ChromaDB, and serves both CLI and web chat flows backed by Ollama models.</p> <ul> <li>Multi-source: OpenBIS ReadTheDocs and DataStore Wiki.js content combined in one vector store.</li> <li>Configurable: Environment-first settings with <code>.env</code> support and CLI overrides.</li> <li>End-to-end pipeline: Scraper \u2192 processor \u2192 vector DB \u2192 RAG query + LangGraph conversation memory.</li> <li>Local-first: Runs entirely on your machine; embeddings, cache, and chat history stay local.</li> <li>Two interfaces: Terminal chatbot and FastAPI/Gradio web UI.</li> </ul>"},{"location":"#quickstart","title":"Quickstart","text":"<p>Follow the step-by-step guide in Tutorials:</p> <p>1) Install dependencies (<code>pip install -e \".[dev]\"</code>), ensure Ollama is running with <code>qwen3</code> and <code>nomic-embed-text</code>.</p> <p>2) Run <code>python init.py</code> to create the <code>.env</code> and data folders.</p> <p>3) Start the full workflow with <code>python main.py</code> or launch the web UI via <code>python -m desi.web.cli --reload</code>.</p>"},{"location":"#choose-your-path","title":"Choose Your Path","text":"<ul> <li>Tutorials: Learn by doing; first run and first query.</li> <li>How-to Guides: Task recipes (scrape only, process only, reindex, change models, troubleshoot).</li> <li>Reference: CLI tables, configuration defaults, file layout, API docs via mkdocstrings.</li> <li>Explanation: Why the architecture works, pipeline details, and design trade-offs.</li> </ul>"},{"location":"#build-these-docs-locally","title":"Build These Docs Locally","text":"<pre><code>pip install -r requirements-docs.txt\nmkdocs serve   # live preview at http://localhost:8000\nmkdocs build   # outputs static site to site/\n</code></pre>"},{"location":"explanations/","title":"Explanations","text":"<p>Conceptual material that clarifies how DeSi works and why design choices were made.</p> <ul> <li>Overview</li> <li>Architecture</li> <li>RAG Pipeline</li> <li>Data Sources</li> <li>Chunking and Retrieval</li> <li>Conversation Memory</li> <li>Security and Privacy</li> </ul>"},{"location":"explanations/architecture/","title":"Architecture","text":"<p>DeSi is organized as a staged pipeline plus conversational interface:</p> <ul> <li>Scraper (<code>desi.scraper.openbis_scraper.OpenbisScraper</code>): crawls ReadTheDocs/Wiki.js pages and stores Markdown in <code>data/raw/**</code>.</li> <li>Processors (<code>DsWikiProcessor</code>, <code>OpenBisProcessor</code>): clean, chunk, and embed content; exports artifacts under <code>data/processed/**</code> and persists embeddings to <code>desi_vectordb/</code>.</li> <li>RAG Engine (<code>RAGQueryEngine</code>): loads ChromaDB, retrieves relevant chunks, and constructs prompts with boosted scores for DataStore content.</li> <li>Conversation Layer (<code>ChatbotEngine</code> + <code>SqliteConversationMemory</code>): LangGraph graph rewrites follow-up questions, calls the RAG engine, and records history in SQLite.</li> <li>Interfaces: terminal CLI (<code>python main.py</code> or <code>python -m desi.query.cli</code>) and FastAPI/Gradio (<code>python -m desi.web.cli</code>) backed by the same conversation engine.</li> </ul> <pre><code>flowchart TD\n    A[User] --&gt;|Question| B[Conversation Engine\\nLangGraph + SQLite memory]\n    B --&gt;|Rewrite &amp; history| C[RAGQueryEngine\\nprompt builder]\n    C --&gt;|Top-k retrieval| D[ChromaDB\\npersisted in desi_vectordb/]\n    D --&gt;|Relevant chunks| C\n    C --&gt;|Prompt with sources| E[Ollama LLM\\nChat &amp; Embeddings]\n    E --&gt;|Answer + citations| B\n    B --&gt;|Response + sources| A\n\n    subgraph Data Prep\n    F[OpenbisScraper] --&gt; G[Raw Markdown\\n data/raw/openbis]\n    H[Wiki.js content] --&gt; I[Raw Markdown\\n data/raw/wikijs]\n    G --&gt; J[OpenBisProcessor]\n    I --&gt; K[DsWikiProcessor]\n    J --&gt; D\n    K --&gt; D\n    end\n</code></pre> <p>The main orchestration (<code>main.py</code>) wires these pieces together, skipping stages when artifacts already exist unless forced via CLI flags.</p>"},{"location":"explanations/chunking-and-retrieval/","title":"Chunking and Retrieval","text":"<p>Chunking strategies aim to preserve context while staying within embedding limits.</p>"},{"location":"explanations/chunking-and-retrieval/#dswiki-dswikiprocessor","title":"DSWiki (<code>DsWikiProcessor</code>)","text":"<ul> <li>Parses YAML frontmatter when present and keeps metadata.</li> <li>Chooses strategy: FAQ-style <code>&lt;details&gt;</code> splitting or structure-based splitting by headings.</li> <li>Cleans Mermaid/PlantUML snippets into text and strips HTML remnants.</li> <li>Enriches metadata (<code>origin=dswiki</code>, <code>section</code>, <code>source</code>, <code>id</code>), then filters very short chunks.</li> </ul>"},{"location":"explanations/chunking-and-retrieval/#openbis-openbisprocessor","title":"openBIS (<code>OpenBisProcessor</code>)","text":"<ul> <li>Normalizes ReadTheDocs artifacts (permalink markers, non-breaking spaces).</li> <li>Chunks by headings with <code>ContentChunker</code> respecting min/max size (<code>100</code> / <code>1000</code> chars defaults).</li> <li>Adds metadata (<code>origin=openbis</code>, reconstructed <code>url</code>, <code>title</code>, <code>section</code>, unique <code>id</code>).</li> </ul>"},{"location":"explanations/chunking-and-retrieval/#embeddings-and-storage","title":"Embeddings and Storage","text":"<ul> <li>Both processors call <code>OllamaEmbeddings(model=\"nomic-embed-text\")</code> and persist via <code>Chroma.from_documents</code>.</li> <li>Chroma collection metadata uses cosine similarity; persisted at <code>DESI_DB_PATH</code>.</li> </ul>"},{"location":"explanations/chunking-and-retrieval/#retrieval","title":"Retrieval","text":"<ul> <li>Candidate pool size is <code>top_k * 4</code>; chunks below the relevance threshold are discarded.</li> <li><code>dswiki</code> chunks receive a positive score boost (<code>dswiki_boost</code>) before sorting to favor DataStore content when scores tie.</li> </ul>"},{"location":"explanations/conversation-memory/","title":"Conversation Memory","text":"<p><code>SqliteConversationMemory</code> (<code>src/desi/query/conversation_engine.py</code>) stores chat history in <code>data/conversation_memory.db</code>.</p> <ul> <li>Schema: <code>conversations(id, session_id, role, content, timestamp)</code> with an index on <code>(session_id, timestamp)</code>.</li> <li><code>history_limit</code> (default <code>20</code>) controls how many past turns are pulled into prompts.</li> <li>Messages are appended after every exchange; <code>clear_session(session_id)</code> deletes them.</li> </ul> <p>The LangGraph workflow in <code>ChatbotEngine</code>: 1. Loads recent messages for the session. 2. Rewrites follow-up questions into standalone queries for better retrieval. 3. Saves both user and assistant messages after generating a response.</p> <p>For the web API, sessions are keyed by a UUID returned in each <code>ChatResponse</code>. To reset context, call <code>POST /api/clear-session</code> or delete the SQLite file.</p>"},{"location":"explanations/data-sources/","title":"Data Sources","text":"<p>DeSi fuses two documentation sources:</p> <ul> <li>openBIS ReadTheDocs: scraped via <code>OpenbisScraper</code> starting from <code>DESI_OPENBIS_URL</code> (default <code>https://openbis.readthedocs.io/en/20.10.0-11/index.html</code>). Files land in <code>data/raw/openbis/**</code>.</li> <li>BAM DataStore Wiki.js: Markdown exports expected under <code>data/raw/wikijs/**</code> (or <code>data/raw/wikijs/daily</code> for the processor defaults).</li> </ul> <p>Metadata added during processing: - <code>origin</code>: <code>openbis</code> or <code>dswiki</code>. - <code>source</code>: relative file path of the chunk. - <code>section</code>: derived from directories (e.g., <code>user-documentation</code>) or inferred titles. - <code>url</code>/<code>title</code> (openBIS only): reconstructed from filenames to the ReadTheDocs URL. - <code>id</code>: stable chunk identifier (<code>openbis-...</code> or <code>dswiki-...</code>).</p> <p>These fields surface in responses so users can see where answers came from.</p>"},{"location":"explanations/overview/","title":"Overview","text":"<p>DeSi (DataStore Helper) is a retrieval-augmented assistant for two knowledge bases: openBIS ReadTheDocs and BAM Data Store Wiki.js. It answers questions with cited context pulled from a local ChromaDB vector store and generated by an Ollama LLM.</p> <p>Key ideas: - Retrieval-Augmented Generation: answers are grounded in stored chunks; sources are surfaced alongside responses. - Local-first: scraping, embeddings, vector DB, and chat history stay on disk; no external API calls. - Composable pipeline: scrapers, processors, and query engine are decoupled so each stage can be run independently. - Conversation-aware: LangGraph workflow rewrites follow-up questions and keeps recent history in SQLite.</p>"},{"location":"explanations/rag-pipeline/","title":"RAG Pipeline","text":"<p><code>RAGQueryEngine</code> (<code>src/desi/query/query.py</code>) orchestrates retrieval and generation.</p> <ol> <li>Load prompt template from <code>prompts/desi_query_prompt.md</code>.</li> <li>Connect to ChromaDB at <code>DESI_DB_PATH</code> using <code>OllamaEmbeddings</code> (<code>DESI_EMBEDDING_MODEL_NAME</code>, default <code>nomic-embed-text</code>).</li> <li>Retrieve: <code>similarity_search_with_relevance_scores</code> fetches a candidate pool (<code>top_k * 4</code>), filters scores below <code>relevance_score_threshold</code> (default <code>0.3</code> in code; CLI defaults to <code>0.7</code>), boosts <code>dswiki</code> chunks by <code>dswiki_boost</code> (0.15 default), and returns the top-k documents.</li> <li>Prompt build: merges conversation history, chunk metadata (origin/source), and the user query into the template.</li> <li>Generate: invokes <code>ChatOllama</code> with <code>DESI_MODEL_NAME</code> (code default <code>gpt-oss:20b</code>, CLI default <code>qwen3</code>), strips <code>&lt;think&gt;</code> blocks, and returns the cleaned answer plus the chunks used.</li> </ol> <p>Relevance tuning: - Increase <code>--relevance-threshold</code> to demand higher similarity (fewer, more precise chunks). - Adjust <code>DESI_RETRIEVAL_TOP_K</code> or CLI <code>top_k</code> to change context breadth. - <code>dswiki_boost</code> biases results toward DataStore content when scores tie.</p>"},{"location":"explanations/security-and-privacy/","title":"Security and Privacy","text":"<p>DeSi is designed to run locally; no external APIs are contacted by default.</p> <ul> <li>Local storage: scraped Markdown (<code>data/raw/**</code>), processed exports (<code>data/processed/**</code>), embeddings (<code>desi_vectordb/</code>), and chat history (<code>data/conversation_memory.db</code>) live on disk.</li> <li>Models: Ollama serves models locally; ensure you trust the model weights you pull.</li> <li>Web API: FastAPI endpoints are unauthenticated by default. Bind to <code>127.0.0.1</code> for local-only access or place behind your own reverse proxy/auth if exposing outside the workstation.</li> <li>Secrets: <code>DESI_SECRET_KEY</code> and <code>DESI_CORS_ORIGINS</code> default to permissive values; override them in production.</li> <li>Data minimization: delete <code>desi_vectordb/</code> or <code>data/conversation_memory.db</code> to purge stored content and history. Re-run processors to rebuild the store.</li> </ul> <p>Always review <code>.env</code> contents and CLI flags before deploying beyond a personal machine.</p>"},{"location":"howtos/","title":"How-to Guides","text":"<p>Practical recipes for specific tasks. Unlike tutorials, these are short and goal-focused.</p> <ul> <li>Configuration</li> <li>Run Scraper Only</li> <li>Run Processor Only</li> <li>Run Query Only</li> <li>Run Web UI</li> <li>Reindex Vector Store</li> <li>Change Ollama Models</li> <li>Troubleshoot</li> </ul>"},{"location":"howtos/change-ollama-models/","title":"Change Ollama Models","text":"<p>Swap the generation or embedding models without touching code.</p>"},{"location":"howtos/change-ollama-models/#configure","title":"Configure","text":"<p>Set environment variables (or add to <code>.env</code>): <pre><code>DESI_MODEL_NAME=llama3.2:3b          # chat/generation model\nDESI_EMBEDDING_MODEL_NAME=nomic-embed-text\n</code></pre> <code>DesiConfig</code> reads these values throughout the pipeline. The query CLI also accepts <code>--llm-model</code> for one-off runs.</p>"},{"location":"howtos/change-ollama-models/#rebuild-embeddings-if-needed","title":"Rebuild Embeddings If Needed","text":"<p>If you change the embedding model, rebuild the vector store: <pre><code>set DESI_EMBEDDING_MODEL_NAME=bge-m3   # PowerShell example\npython -m desi.processor.cli --chroma-dir desi_vectordb\n</code></pre></p>"},{"location":"howtos/change-ollama-models/#validate","title":"Validate","text":"<ol> <li>Ensure Ollama has the models: <code>ollama pull llama3.2:3b</code> (or your choice).</li> <li>Run a quick query:    <pre><code>DESI_MODEL_NAME=llama3.2:3b python -m desi.query.cli --db-path desi_vectordb\n</code></pre></li> <li>Check the startup logs for the model names being loaded.</li> </ol>"},{"location":"howtos/configuration/","title":"Configuration","text":"<p>DeSi reads settings from environment variables, optionally loaded from a <code>.env</code> file by <code>DesiConfig</code>. CLI flags that accept <code>--config</code> pass a custom env file path; environment variables always win over file values.</p>"},{"location":"howtos/configuration/#use-a-env-file","title":"Use a .env File","text":"<ol> <li>Copy the template: <code>.env.example</code> \u2192 <code>.env</code> (or run <code>python init.py</code>).</li> <li>Edit values, for example:    <pre><code>DESI_DB_PATH=desi_vectordb\nDESI_MODEL_NAME=gpt-oss:20b\nDESI_EMBEDDING_MODEL_NAME=nomic-embed-text\nDESI_WEB_PORT=5000\n</code></pre></li> <li>Run commands normally; <code>DesiConfig</code> loads <code>.env</code> from the project root automatically.</li> </ol>"},{"location":"howtos/configuration/#override-with-environment-variables","title":"Override with Environment Variables","text":"<p>Any variable can be set per command: <pre><code>set DESI_MODEL_NAME=qwen3\npython main.py\n</code></pre> Explicit environment variables override <code>.env</code> values.</p>"},{"location":"howtos/configuration/#point-to-a-custom-config-file","title":"Point to a Custom Config File","text":"<p>Several CLIs accept <code>--config &lt;file&gt;</code>: <pre><code>python main.py --config ./staging.env\npython -m desi.web.cli --config ./staging.env --reload\n</code></pre> <code>DesiConfig</code> loads that file first, then applies environment overrides.</p>"},{"location":"howtos/configuration/#what-desiconfig-provides","title":"What DesiConfig Provides","text":"<p>See Configuration Reference for the full variable list, defaults, and meanings drawn directly from <code>src/desi/utils/config.py</code>.</p>"},{"location":"howtos/reindex-vector-store/","title":"Reindex Vector Store","text":"<p>Rebuild ChromaDB when prompts, chunking, or source data change.</p>"},{"location":"howtos/reindex-vector-store/#steps","title":"Steps","text":"<ol> <li>Stop any running chat/web sessions.</li> <li>Remove the existing store (or move it aside):    <pre><code>rmdir /s /q desi_vectordb   # Windows PowerShell\n# rm -rf desi_vectordb      # macOS/Linux\n</code></pre></li> <li>(Optional) Refresh raw data:    <pre><code>python -m desi.scraper.cli --url https://openbis.readthedocs.io/en/20.10.0-11/ --output data/raw/openbis\n</code></pre></li> <li>Run processors to recreate embeddings:    <pre><code>python -m desi.processor.cli --dswiki-input data/raw/wikijs --openbis-input data/raw/openbis --chroma-dir desi_vectordb\n</code></pre></li> <li>Verify the store exists (<code>desi_vectordb/chroma.sqlite3</code> should be present) and restart your preferred interface (<code>python main.py</code> or <code>python -m desi.query.cli</code>).</li> </ol>"},{"location":"howtos/reindex-vector-store/#tips","title":"Tips","text":"<ul> <li>Use <code>--no-delete</code> only when you intentionally want to append to the current store.</li> <li>If you change <code>DESI_COLLECTION_NAME</code>, reprocess so chunks land in the new collection.</li> </ul>"},{"location":"howtos/run-processor-only/","title":"Run Processor Only","text":"<p>Convert scraped Markdown into cleaned chunks and persist them to ChromaDB.</p>"},{"location":"howtos/run-processor-only/#command","title":"Command","text":"<pre><code>python -m desi.processor.cli [options]\n</code></pre>"},{"location":"howtos/run-processor-only/#arguments","title":"Arguments","text":"<ul> <li><code>--dswiki-input</code> (default <code>./data/raw/wikijs/daily</code>): source directory for Wiki.js Markdown.</li> <li><code>--openbis-input</code> (default <code>./data/raw/openbis/improved</code>): source directory for openBIS Markdown.</li> <li><code>--output-dir</code> (default <code>./data/processed</code>): base folder for exported chunks (CSV/JSON/JSONL per source).</li> <li><code>--chroma-dir</code> (default <code>./desi_vectordb</code>): Chroma persistence directory.</li> <li><code>--no-delete</code>: append to existing Chroma data instead of deleting it first.</li> <li><code>--verbose</code>: enable DEBUG logs.</li> </ul> <p><code>DsWikiProcessor</code> and <code>OpenBisProcessor</code> run sequentially. Each enriches metadata, chunks content, exports artifacts, and writes embeddings via <code>OllamaEmbeddings</code> into the same Chroma collection.</p>"},{"location":"howtos/run-processor-only/#examples","title":"Examples","text":"<ul> <li>Process existing raw data into a fresh vector store:   <pre><code>python -m desi.processor.cli --dswiki-input data/raw/wikijs --openbis-input data/raw/openbis --chroma-dir desi_vectordb\n</code></pre></li> <li>Keep the current database and add new chunks:   <pre><code>python -m desi.processor.cli --no-delete\n</code></pre></li> </ul> <p>If either input directory is missing, the CLI exits with an error\u2014run the scraper first or adjust paths.</p>"},{"location":"howtos/run-query-only/","title":"Run Query Only","text":"<p>Launch the chatbot directly against an existing vector store.</p>"},{"location":"howtos/run-query-only/#command","title":"Command","text":"<pre><code>python -m desi.query.cli [options]\n</code></pre>"},{"location":"howtos/run-query-only/#arguments","title":"Arguments","text":"<ul> <li><code>--db-path</code> (default <code>./desi_vectordb</code>): Chroma persistence directory to load.</li> <li><code>--prompt-template</code> (default <code>./prompts/desi_query_prompt.md</code>): prompt template file.</li> <li><code>--memory-db-path</code> (default <code>./data/conversation_memory.db</code>): SQLite database for conversation history.</li> <li><code>--llm-model</code> (default <code>qwen3</code> in the CLI; code defaults in <code>DesiConfig</code> use <code>gpt-oss:20b</code> for the main pipeline).</li> <li><code>--relevance-threshold</code> (default <code>0.7</code>): minimum similarity score to accept a chunk.</li> <li><code>--verbose</code>: enable DEBUG logging.</li> </ul> <p>The CLI wires <code>RAGQueryEngine</code>, <code>SqliteConversationMemory</code>, and a <code>ChatOllama</code> instance for query rewriting. Ollama must be running; otherwise the CLI exits early.</p>"},{"location":"howtos/run-query-only/#examples","title":"Examples","text":"<ul> <li>Use a custom vector store and prompt:   <pre><code>python -m desi.query.cli --db-path ./desi_vectordb --prompt-template ./prompts/desi_query_prompt.md --relevance-threshold 0.5\n</code></pre></li> <li>Change the generation model for a session:   <pre><code>DESI_MODEL_NAME=llama3.2:3b python -m desi.query.cli --llm-model llama3.2:3b\n</code></pre></li> </ul>"},{"location":"howtos/run-scraper-only/","title":"Run Scraper Only","text":"<p>Use the scraper CLI to download documentation as Markdown without processing or embedding.</p>"},{"location":"howtos/run-scraper-only/#command","title":"Command","text":"<pre><code>python -m desi.scraper.cli --url &lt;base-url&gt; --output &lt;path&gt;\n</code></pre>"},{"location":"howtos/run-scraper-only/#arguments","title":"Arguments","text":"<ul> <li><code>--url</code> (required): starting page to crawl (e.g., <code>https://openbis.readthedocs.io/en/20.10.0-11/</code>).</li> <li><code>--output</code> (required): directory where <code>.md</code> files are written (created if missing).</li> </ul> <p>The CLI wraps <code>OpenbisScraper</code>, which keeps requests within the base domain and saves each page\u2019s main content as Markdown.</p>"},{"location":"howtos/run-scraper-only/#examples","title":"Examples","text":"<ul> <li>Scrape openBIS docs to the default raw folder:   <pre><code>python -m desi.scraper.cli --url https://openbis.readthedocs.io/en/20.10.0-11/ --output data/raw/openbis\n</code></pre></li> <li>Limit pages via code config: set <code>DESI_MAX_PAGES_PER_SCRAPER</code> to cap crawl depth.</li> </ul>"},{"location":"howtos/run-scraper-only/#next-step","title":"Next Step","text":"<p>Run the processor to chunk and embed the scraped files (see Run Processor Only).</p>"},{"location":"howtos/run-web-ui/","title":"Run Web UI","text":"<p>Start the FastAPI + Gradio interface served by uvicorn.</p>"},{"location":"howtos/run-web-ui/#command","title":"Command","text":"<pre><code>python -m desi.web.cli [options]\n</code></pre>"},{"location":"howtos/run-web-ui/#arguments","title":"Arguments","text":"<ul> <li><code>--host</code> (default from <code>DesiConfig.web_host</code>, fallback <code>0.0.0.0</code>): bind address.</li> <li><code>--port</code> (default from <code>DesiConfig.web_port</code>, fallback <code>5000</code>): listening port.</li> <li><code>--reload</code>: enable auto-reload for development.</li> <li><code>--config &lt;file&gt;</code>: optional <code>.env</code> path to load before reading environment variables.</li> </ul>"},{"location":"howtos/run-web-ui/#example","title":"Example","text":"<p><pre><code>python -m desi.web.cli --host 127.0.0.1 --port 7860 --reload\n</code></pre> The CLI loads configuration, logs the resolved host/port, updates <code>desi.web.app.api_base_url</code>, and then runs <code>uvicorn desi.web.app:app</code>.</p>"},{"location":"howtos/run-web-ui/#health-checks","title":"Health Checks","text":"<ul> <li><code>GET /health</code>: verifies the conversation engine initialized.</li> <li><code>POST /api/chat</code>: accepts <code>{ \"message\": \"...\", \"session_id\": \"&lt;optional&gt;\" }</code> and returns the model response plus sources.</li> <li><code>POST /api/clear-session</code>: clears memory for a session.</li> </ul> <p>If FastAPI or Gradio imports fail, the CLI reports the missing packages and exits.</p>"},{"location":"howtos/troubleshoot/","title":"Troubleshoot","text":"<p>Common issues and quick fixes when running DeSi locally.</p> <ul> <li>Ollama not running: Start the service (<code>ollama serve</code>) and ensure the API is reachable at <code>http://localhost:11434</code>. Re-run <code>python init.py</code> to verify.</li> <li>Missing models: Pull required models (<code>ollama pull nomic-embed-text</code> and your chat model). Mismatched names raise errors when <code>ChatOllama</code> or <code>OllamaEmbeddings</code> initialize.</li> <li>Empty vector DB: If answers show \u201cNo sources were used,\u201d check that <code>desi_vectordb/chroma.sqlite3</code> exists. Rebuild via <code>python -m desi.processor.cli --force</code> or delete the directory and reprocess.</li> <li>Scraping failures: Confirm the target URL is reachable and within the same domain. Set <code>DESI_MAX_PAGES_PER_SCRAPER</code> to limit crawl scope. Ensure the <code>--output</code> path exists or let the scraper create it.</li> <li>Slow responses: Use a lighter chat model, reduce <code>DESI_RETRIEVAL_TOP_K</code>, or lower <code>--relevance-threshold</code> slightly to avoid over-fetching. Hardware limitations on embeddings or model size can dominate latency.</li> <li>Verbose logs: Set <code>DESI_LOG_LEVEL=DEBUG</code> or use <code>--verbose</code> on processor/query CLIs to see chunking, retrieval scores, and requests.</li> <li>Stale memory: Delete <code>data/conversation_memory.db</code> or call <code>POST /api/clear-session</code> (web) if conversations feel \u201cstuck.\u201d</li> </ul>"},{"location":"reference/","title":"Reference","text":"<p>Authoritative details for commands, configuration, file layout, and API objects.</p> <ul> <li>Command Line</li> <li>Configuration</li> <li>File Layout</li> <li>API</li> </ul>"},{"location":"reference/command-line/","title":"Command Line","text":"<p>All commands are Python entry points shipped in the repository. Paths are relative to the project root and assume your virtual environment is active (<code>pip install -e .</code>).</p>"},{"location":"reference/command-line/#scraper-cli-python-m-desiscrapercli","title":"Scraper CLI (<code>python -m desi.scraper.cli</code>)","text":"<p>Download documentation pages to Markdown using <code>OpenbisScraper</code>.</p> Argument Type / Default Description <code>--url</code> required Base URL to crawl (e.g., <code>https://openbis.readthedocs.io/en/20.10.0-11/</code>). <code>--output</code> required Directory where Markdown files are written. Created if missing. <p>Example: <pre><code>python -m desi.scraper.cli --url https://openbis.readthedocs.io/en/20.10.0-11/ --output data/raw/openbis\n</code></pre></p>"},{"location":"reference/command-line/#processor-cli-python-m-desiprocessorcli","title":"Processor CLI (<code>python -m desi.processor.cli</code>)","text":"<p>Chunk scraped Markdown and write embeddings to ChromaDB.</p> Argument Type / Default Description <code>--dswiki-input</code> str, <code>./data/raw/wikijs/daily</code> Input folder for Wiki.js Markdown. <code>--openbis-input</code> str, <code>./data/raw/openbis/improved</code> Input folder for openBIS Markdown. <code>--output-dir</code> str, <code>./data/processed</code> Base folder for processed exports. <code>--chroma-dir</code> str, <code>./desi_vectordb</code> Chroma persistence directory. <code>--no-delete</code> flag Append to the existing Chroma DB instead of deleting it first. <code>--verbose</code> flag Enable DEBUG logging. <p>Examples: <pre><code>python -m desi.processor.cli --dswiki-input data/raw/wikijs --openbis-input data/raw/openbis --chroma-dir desi_vectordb\npython -m desi.processor.cli --no-delete --verbose\n</code></pre></p>"},{"location":"reference/command-line/#query-cli-python-m-desiquerycli","title":"Query CLI (<code>python -m desi.query.cli</code>)","text":"<p>Run the terminal chatbot against an existing vector store.</p> Argument Type / Default Description <code>--db-path</code> str, <code>./desi_vectordb</code> Chroma persistence directory. <code>--prompt-template</code> str, <code>./prompts/desi_query_prompt.md</code> Prompt template file for the RAG engine. <code>--memory-db-path</code> str, <code>./data/conversation_memory.db</code> SQLite database for conversation history. <code>--llm-model</code> str, <code>qwen3</code> Ollama model for generation and rewriting. <code>--relevance-threshold</code> float, <code>0.7</code> Minimum similarity score to keep a chunk. <code>--verbose</code> flag Enable DEBUG logging. <p>Example: <pre><code>python -m desi.query.cli --db-path desi_vectordb --prompt-template prompts/desi_query_prompt.md --relevance-threshold 0.5\n</code></pre></p>"},{"location":"reference/command-line/#web-cli-python-m-desiwebcli","title":"Web CLI (<code>python -m desi.web.cli</code>)","text":"<p>Launch the FastAPI + Gradio interface via uvicorn.</p> Argument Type / Default Description <code>--host</code> str, config default <code>0.0.0.0</code> Bind address; CLI overrides config. <code>--port</code> int, config default <code>5000</code> Port to listen on. <code>--reload</code> flag Auto-reload in development. <code>--config</code> path, optional <code>.env</code> file to load before environment variables. <p>Example: <pre><code>python -m desi.web.cli --host 127.0.0.1 --port 7860 --reload\n</code></pre></p>"},{"location":"reference/command-line/#main-pipeline-python-mainpy","title":"Main Pipeline (<code>python main.py</code>)","text":"<p>Orchestrates scraping, processing, and chat in one command.</p> Argument Type / Default Description <code>--web</code> flag Start the web interface instead of the terminal chat. <code>--skip-scraping</code> flag Skip scraping even if no raw data exists. <code>--skip-processing</code> flag Skip processing and go straight to chat. <code>--force-scraping</code> flag Re-run scraping even if raw data exists. <code>--force-processing</code> flag Re-run processing even if Chroma exists. <code>--config</code> path, optional <code>.env</code> file to load. Environment variables still override. <p>Examples: <pre><code>python main.py --force-scraping --force-processing\npython main.py --web --config staging.env\n</code></pre></p>"},{"location":"reference/configuration/","title":"Configuration","text":"<p><code>DesiConfig</code> (<code>src/desi/utils/config.py</code>) is the source of truth. It loads an optional <code>.env</code> file, then environment variables. Defaults below come from code; README examples may differ (for example, README suggests <code>qwen3</code> while the code default for <code>DESI_MODEL_NAME</code> is <code>gpt-oss:20b</code>).</p> Variable Default (code) Meaning / Example <code>DESI_DB_PATH</code> <code>desi_vectordb</code> Chroma persistence directory. <code>DESI_COLLECTION_NAME</code> <code>desi_docs</code> Chroma collection name. <code>DESI_MEMORY_DB_PATH</code> <code>data/conversation_memory.db</code> SQLite chat history file. <code>DESI_MODEL_NAME</code> <code>gpt-oss:20b</code> Ollama chat model (README examples use <code>qwen3</code>). <code>DESI_EMBEDDING_MODEL_NAME</code> <code>nomic-embed-text</code> Ollama embedding model. <code>DESI_DATA_DIR</code> <code>data</code> Base data directory for scraping. <code>DESI_PROCESSED_DATA_DIR</code> <code>data/processed</code> Output folder for processed chunks. <code>DESI_OPENBIS_URL</code> <code>https://openbis.readthedocs.io/en/20.10.0-11/index.html</code> Default openBIS ReadTheDocs start URL. <code>DESI_WIKIJS_URL</code> <code>https://datastore.bam.de/en/home</code> Default Wiki.js entry URL. <code>DESI_MAX_PAGES_PER_SCRAPER</code> <code>None</code> Optional limit on pages to crawl (integer). <code>DESI_MIN_CHUNK_SIZE</code> <code>100</code> Minimum characters per chunk. <code>DESI_MAX_CHUNK_SIZE</code> <code>1000</code> Maximum characters per chunk. <code>DESI_CHUNK_OVERLAP</code> <code>50</code> Overlap between chunks (currently used in <code>DesiConfig</code>, processors implement their own sizing). <code>DESI_RETRIEVAL_TOP_K</code> <code>5</code> Number of chunks to retrieve (used by configs; query CLI uses <code>top_k=5</code> internally). <code>DESI_HISTORY_LIMIT</code> <code>20</code> Conversation turns to keep in memory. <code>DESI_LOG_LEVEL</code> <code>INFO</code> Logging level for <code>setup_logging</code>. <code>DESI_WEB_HOST</code> <code>0.0.0.0</code> Bind address for web UI. <code>DESI_WEB_PORT</code> <code>5000</code> Port for web UI. <code>DESI_WEB_DEBUG</code> <code>false</code> Enable reload/debug mode. <code>DESI_SECRET_KEY</code> <code>desi_secret_key_change_in_production</code> Flask/FastAPI secret key. <code>DESI_CORS_ORIGINS</code> <code>*</code> Allowed CORS origins. <p>Environment variables override values loaded from <code>--config</code> files and <code>.env</code> files.</p>"},{"location":"reference/file-layout/","title":"File Layout","text":"<p>Key locations in the repository (relative to the project root).</p> <ul> <li><code>src/desi/</code>: Python package source.</li> <li><code>scraper/openbis_scraper.py</code>: OpenBIS ReadTheDocs crawler.</li> <li><code>processor/ds_processor.py</code> and <code>processor/openbis_processor.py</code>: chunking and embedding pipelines.</li> <li><code>query/query.py</code>: <code>RAGQueryEngine</code>.</li> <li><code>query/conversation_engine.py</code>: LangGraph-based chatbot and SQLite memory.</li> <li><code>web/app.py</code>: FastAPI + Gradio app and Pydantic models; <code>web/cli.py</code> for launching.</li> <li><code>utils/config.py</code>: <code>DesiConfig</code> environment handling.</li> <li><code>prompts/desi_query_prompt.md</code>: prompt template used by the query engine.</li> <li><code>data/raw/</code>: scraped Markdown (<code>openbis/</code>, <code>wikijs/</code>).</li> <li><code>data/processed/</code>: exported chunks (<code>openbis/</code>, <code>wikijs/</code>), CSV/JSON/JSONL.</li> <li><code>desi_vectordb/</code>: ChromaDB persistence (created by processors).</li> <li><code>data/conversation_memory.db</code>: SQLite conversation memory.</li> <li><code>main.py</code>: orchestrated CLI (scrape \u2192 process \u2192 chat/web).</li> <li><code>init.py</code>: setup helper (checks Ollama, creates folders, copies <code>.env</code>).</li> <li><code>assets/</code>, <code>src/desi/web/static/</code>: static web assets (if added).</li> <li><code>tests/</code>: test suite.</li> <li><code>README.md</code>: original project overview; source material for these docs.</li> </ul>"},{"location":"reference/api/","title":"API Reference","text":"<p>API pages are generated with <code>mkdocstrings</code> from docstrings in <code>src/desi</code>. Browse modules below for signatures and inline documentation. For usage patterns, see Tutorials and How-to guides.</p> <ul> <li>Utils</li> <li>Scraper</li> <li>Processor</li> <li>Query</li> <li>Web</li> </ul>"},{"location":"reference/api/processor/","title":"Processor API","text":"<p>RAG Processor for ReadtheDocs Markdown Content</p> <p>This script processes scraped Markdown files. It chunks the content using a header-aware strategy, generates embeddings (using Ollama or dummy data), and saves the output to JSON and CSV files for a RAG pipeline.</p>"},{"location":"reference/api/processor/#desi.processor.ds_processor.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.ds_processor.ROOT_DIRECTORY","title":"<code>ROOT_DIRECTORY = './data/raw/wikijs'</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.ds_processor.OUTPUT_DIRECTORY","title":"<code>OUTPUT_DIRECTORY = './data/processed/wikijs'</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.ds_processor.CHROMA_PERSIST_DIRECTORY","title":"<code>CHROMA_PERSIST_DIRECTORY = './desi_vectordb'</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.ds_processor.processor","title":"<code>processor = DsWikiProcessor(root_directory=ROOT_DIRECTORY, output_directory=OUTPUT_DIRECTORY, chroma_persist_directory=CHROMA_PERSIST_DIRECTORY)</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.ds_processor.Document","title":"<code>Document</code>","text":""},{"location":"reference/api/processor/#desi.processor.ds_processor.Document.page_content","title":"<code>page_content = page_content</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.ds_processor.Document.metadata","title":"<code>metadata = metadata</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.ds_processor.Document.__init__","title":"<code>__init__(page_content, metadata)</code>","text":""},{"location":"reference/api/processor/#desi.processor.ds_processor.Document.__repr__","title":"<code>__repr__()</code>","text":""},{"location":"reference/api/processor/#desi.processor.ds_processor.CustomJSONEncoder","title":"<code>CustomJSONEncoder</code>","text":"<p>               Bases: <code>JSONEncoder</code></p> <p>A custom JSON encoder to handle datetime objects by converting them to ISO format strings.</p>"},{"location":"reference/api/processor/#desi.processor.ds_processor.CustomJSONEncoder.default","title":"<code>default(o)</code>","text":""},{"location":"reference/api/processor/#desi.processor.ds_processor.DsWikiProcessor","title":"<code>DsWikiProcessor</code>","text":"<p>Encapsulates the entire processing pipeline for the DSWiki data source.</p>"},{"location":"reference/api/processor/#desi.processor.ds_processor.DsWikiProcessor.root_directory","title":"<code>root_directory = root_directory</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.ds_processor.DsWikiProcessor.output_directory","title":"<code>output_directory = output_directory</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.ds_processor.DsWikiProcessor.chroma_persist_directory","title":"<code>chroma_persist_directory = chroma_persist_directory</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.ds_processor.DsWikiProcessor.__init__","title":"<code>__init__(root_directory, output_directory, chroma_persist_directory)</code>","text":"<p>Initializes the processor with necessary directory paths.</p>"},{"location":"reference/api/processor/#desi.processor.ds_processor.DsWikiProcessor.process","title":"<code>process()</code>","text":"<p>Executes the full processing pipeline for the DSWiki data source. This method replaces the original run_dswiki_processing function.</p>"},{"location":"reference/api/processor/#desi.processor.openbis_processor.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.openbis_processor.OLLAMA_AVAILABLE","title":"<code>OLLAMA_AVAILABLE = True</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.openbis_processor.embeddings_model","title":"<code>embeddings_model = OllamaEmbeddings(model='nomic-embed-text')</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.openbis_processor.ROOT_DIRECTORY","title":"<code>ROOT_DIRECTORY = './data/raw/openbis'</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.openbis_processor.OUTPUT_DIRECTORY","title":"<code>OUTPUT_DIRECTORY = './data/processed/openbis'</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.openbis_processor.CHROMA_PERSIST_DIRECTORY","title":"<code>CHROMA_PERSIST_DIRECTORY = './desi_vectordb'</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.openbis_processor.processor","title":"<code>processor = OpenBisProcessor(root_directory=ROOT_DIRECTORY, output_directory=OUTPUT_DIRECTORY, chroma_persist_directory=CHROMA_PERSIST_DIRECTORY)</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.openbis_processor.CustomJSONEncoder","title":"<code>CustomJSONEncoder</code>","text":"<p>               Bases: <code>JSONEncoder</code></p>"},{"location":"reference/api/processor/#desi.processor.openbis_processor.CustomJSONEncoder.default","title":"<code>default(o)</code>","text":""},{"location":"reference/api/processor/#desi.processor.openbis_processor.ContentChunker","title":"<code>ContentChunker</code>","text":"<p>Class for chunking Markdown content into smaller, context-aware pieces.</p>"},{"location":"reference/api/processor/#desi.processor.openbis_processor.ContentChunker.min_chunk_size","title":"<code>min_chunk_size = min_chunk_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.openbis_processor.ContentChunker.max_chunk_size","title":"<code>max_chunk_size = max_chunk_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.openbis_processor.ContentChunker.__init__","title":"<code>__init__(min_chunk_size=100, max_chunk_size=1000)</code>","text":"<p>Initialize the chunker. Context is maintained by prepending headers, which is a more robust method.</p> <p>Parameters:</p> Name Type Description Default <code>min_chunk_size</code> <code>int</code> <p>The minimum size of a chunk in characters.</p> <code>100</code> <code>max_chunk_size</code> <code>int</code> <p>The maximum size of a chunk in characters.</p> <code>1000</code>"},{"location":"reference/api/processor/#desi.processor.openbis_processor.ContentChunker.chunk_content","title":"<code>chunk_content(content)</code>","text":"<p>Chunk the Markdown content into smaller pieces based on headers.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The Markdown content to chunk.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of content chunks.</p>"},{"location":"reference/api/processor/#desi.processor.openbis_processor.OpenBisProcessor","title":"<code>OpenBisProcessor</code>","text":"<p>Encapsulates the entire processing pipeline for the openBIS data source.</p>"},{"location":"reference/api/processor/#desi.processor.openbis_processor.OpenBisProcessor.root_directory","title":"<code>root_directory = root_directory</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.openbis_processor.OpenBisProcessor.output_directory","title":"<code>output_directory = output_directory</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.openbis_processor.OpenBisProcessor.chroma_persist_directory","title":"<code>chroma_persist_directory = chroma_persist_directory</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/processor/#desi.processor.openbis_processor.OpenBisProcessor.__init__","title":"<code>__init__(root_directory, output_directory, chroma_persist_directory)</code>","text":""},{"location":"reference/api/processor/#desi.processor.openbis_processor.OpenBisProcessor.process","title":"<code>process()</code>","text":"<p>Executes the full processing pipeline. Replaces run_openbis_processing.</p>"},{"location":"reference/api/query/","title":"Query API","text":"<p>RAG Query Engine</p> <p>This module provides the core functionality for querying the vector database and generating answers using a Retrieval-Augmented Generation (RAG) pipeline. It connects to a persistent ChromaDB vector store and uses Ollama for both embedding and language model generation.</p> <p>Main Conversation Engine for the Chatbot using LangGraph.</p> <p>This script orchestrates the conversational workflow, managing user interaction, short-term memory with SQLite, and interfacing with the RAG query engine within a structured, extensible LangGraph graph.</p>"},{"location":"reference/api/query/#desi.query.query.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.OLLAMA_AVAILABLE","title":"<code>OLLAMA_AVAILABLE = True</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.CHROMA_PERSIST_DIRECTORY","title":"<code>CHROMA_PERSIST_DIRECTORY = './desi_vectordb'</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.DSWIKI_BOOST_VALUE","title":"<code>DSWIKI_BOOST_VALUE = 0.1</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.RELEVANCE_THRESHOLD","title":"<code>RELEVANCE_THRESHOLD = 0.4</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.PROMPT_TEMPLATE_PATH","title":"<code>PROMPT_TEMPLATE_PATH = './prompts/desi_query_prompt.md'</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.query_engine","title":"<code>query_engine = RAGQueryEngine(chroma_persist_directory=CHROMA_PERSIST_DIRECTORY, dswiki_boost=DSWIKI_BOOST_VALUE, prompt_template_path=PROMPT_TEMPLATE_PATH, relevance_score_threshold=RELEVANCE_THRESHOLD)</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.user_query","title":"<code>user_query = input('Ask a question: ')</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.displayed_sources","title":"<code>displayed_sources = set()</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.source","title":"<code>source = doc.metadata.get('source', 'N/A')</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.raw_origin","title":"<code>raw_origin = doc.metadata.get('origin', 'N/A')</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.display_origin","title":"<code>display_origin = 'DataStore Wiki'</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.RAGQueryEngine","title":"<code>RAGQueryEngine</code>","text":"<p>Manages the entire RAG pipeline from query to answer.</p>"},{"location":"reference/api/query/#desi.query.query.RAGQueryEngine.chroma_persist_directory","title":"<code>chroma_persist_directory = chroma_persist_directory</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.RAGQueryEngine.embedding_model_name","title":"<code>embedding_model_name = embedding_model</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.RAGQueryEngine.llm_model_name","title":"<code>llm_model_name = llm_model</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.RAGQueryEngine.dswiki_boost","title":"<code>dswiki_boost = dswiki_boost</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.RAGQueryEngine.relevance_score_threshold","title":"<code>relevance_score_threshold = relevance_score_threshold</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.RAGQueryEngine.prompt_template","title":"<code>prompt_template = self._load_prompt_template(prompt_template_path)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.RAGQueryEngine.embedding_model","title":"<code>embedding_model = OllamaEmbeddings(model=(self.embedding_model_name))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.RAGQueryEngine.vector_store","title":"<code>vector_store = Chroma(persist_directory=(self.chroma_persist_directory), embedding_function=(self.embedding_model))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.RAGQueryEngine.llm","title":"<code>llm = ChatOllama(model=(self.llm_model_name))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.query.RAGQueryEngine.__init__","title":"<code>__init__(chroma_persist_directory, prompt_template_path, embedding_model='nomic-embed-text', llm_model='qwen3', dswiki_boost=0.15, relevance_score_threshold=0.3)</code>","text":"<p>Initializes the RAG query engine.</p> <p>Parameters:</p> Name Type Description Default <code>chroma_persist_directory</code> <code>str</code> <p>The directory where the ChromaDB                             vector store is persisted.</p> required <code>embedding_model</code> <code>str</code> <p>The name of the Ollama model to use for                    generating embeddings.</p> <code>'nomic-embed-text'</code> <code>llm_model</code> <code>str</code> <p>The name of the Ollama model to use for generating              answers.</p> <code>'qwen3'</code> <code>dswiki_boost</code> <code>float</code> <p>A value to add to the relevance score of chunks                   from 'dswiki' to prioritize them.</p> <code>0.15</code> <code>relevance_score_threshold</code> <code>float</code> <p>The minimum similarity score for a chunk                                to be considered relevant. Chunks with a                                score below this are discarded.</p> <code>0.3</code>"},{"location":"reference/api/query/#desi.query.query.RAGQueryEngine.retrieve_relevant_chunks","title":"<code>retrieve_relevant_chunks(query, top_k=5)</code>","text":"<p>Retrieves the most relevant document chunks for a given query from ChromaDB, applying a score boost to chunks from the 'dswiki' origin.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The user's query.</p> required <code>top_k</code> <code>int</code> <p>The number of top relevant chunks to retrieve.</p> <code>5</code> <p>Returns:</p> Type Description <code>List[Document]</code> <p>List[Document]: A list of LangChain Document objects containing the             retrieved content and metadata.</p>"},{"location":"reference/api/query/#desi.query.query.RAGQueryEngine.generate_answer","title":"<code>generate_answer(prompt)</code>","text":"<p>Generates an answer using the LLM based on the query and relevant chunks.</p>"},{"location":"reference/api/query/#desi.query.query.RAGQueryEngine.query","title":"<code>query(query, conversation_history=None, top_k=5)</code>","text":"<p>Executes the full RAG pipeline for a given query.</p>"},{"location":"reference/api/query/#desi.query.conversation_engine.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.CHROMA_PERSIST_DIRECTORY","title":"<code>CHROMA_PERSIST_DIRECTORY = './desi_vectordb'</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.PROMPT_TEMPLATE_PATH","title":"<code>PROMPT_TEMPLATE_PATH = './prompts/desi_query_prompt.md'</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.SQLITE_DB_PATH","title":"<code>SQLITE_DB_PATH = './data/conversation_memory.db'</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.CONVERSATION_HISTORY_LIMIT","title":"<code>CONVERSATION_HISTORY_LIMIT = 20</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.DSWIKI_BOOST_VALUE","title":"<code>DSWIKI_BOOST_VALUE = 0.1</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.RELEVANCE_THRESHOLD","title":"<code>RELEVANCE_THRESHOLD = 0.4</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.LLM_MODEL","title":"<code>LLM_MODEL = 'qwen3'</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.rag_engine","title":"<code>rag_engine = RAGQueryEngine(chroma_persist_directory=CHROMA_PERSIST_DIRECTORY, dswiki_boost=DSWIKI_BOOST_VALUE, llm_model=LLM_MODEL, prompt_template_path=PROMPT_TEMPLATE_PATH, relevance_score_threshold=RELEVANCE_THRESHOLD)</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.conversation_memory","title":"<code>conversation_memory = SqliteConversationMemory(db_path=SQLITE_DB_PATH, history_limit=CONVERSATION_HISTORY_LIMIT)</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.rewrite_llm","title":"<code>rewrite_llm = ChatOllama(model=LLM_MODEL)</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.chatbot","title":"<code>chatbot = ChatbotEngine(rag_engine=rag_engine, memory=conversation_memory, rewrite_llm=rewrite_llm)</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.SqliteConversationMemory","title":"<code>SqliteConversationMemory</code>","text":"<p>SQLite-based conversation memory for storing and managing short-term context.</p>"},{"location":"reference/api/query/#desi.query.conversation_engine.SqliteConversationMemory.db_path","title":"<code>db_path = db_path</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.SqliteConversationMemory.history_limit","title":"<code>history_limit = history_limit</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.SqliteConversationMemory.__init__","title":"<code>__init__(db_path='./data/chatbot_memory.db', history_limit=20)</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.SqliteConversationMemory.add_message","title":"<code>add_message(session_id, role, content)</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.SqliteConversationMemory.get_recent_messages","title":"<code>get_recent_messages(session_id)</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.SqliteConversationMemory.clear_session","title":"<code>clear_session(session_id)</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.GraphState","title":"<code>GraphState</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Represents the state of our conversation graph.</p> <p>Attributes:</p> Name Type Description <code>session_id</code> <code>str</code> <p>The unique ID for the conversation.</p> <code>user_query</code> <code>str</code> <p>The latest query from the user.</p> <code>history</code> <code>List[Dict]</code> <p>The recent conversation history.</p> <code>response</code> <code>str</code> <p>The final response from the assistant.</p> <code>sources</code> <code>List[Dict]</code> <p>A list of sources used by the RAG engine.</p>"},{"location":"reference/api/query/#desi.query.conversation_engine.GraphState.session_id","title":"<code>session_id</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.GraphState.user_query","title":"<code>user_query</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.GraphState.rewritten_query","title":"<code>rewritten_query</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.GraphState.history","title":"<code>history</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.GraphState.response","title":"<code>response</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.GraphState.sources","title":"<code>sources</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.ChatbotEngine","title":"<code>ChatbotEngine</code>","text":"<p>The main engine to run the chatbot conversation using a LangGraph workflow.</p>"},{"location":"reference/api/query/#desi.query.conversation_engine.ChatbotEngine.rag_engine","title":"<code>rag_engine = rag_engine</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.ChatbotEngine.memory","title":"<code>memory = memory</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.ChatbotEngine.rewrite_llm","title":"<code>rewrite_llm = rewrite_llm</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.ChatbotEngine.graph","title":"<code>graph = self._build_graph()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.ChatbotEngine.__init__","title":"<code>__init__(rag_engine, memory, rewrite_llm)</code>","text":""},{"location":"reference/api/query/#desi.query.conversation_engine.ChatbotEngine.rewrite_query_node","title":"<code>rewrite_query_node(state)</code>","text":"<p>Node that rewrites the user's query to be self-contained for better retrieval.</p>"},{"location":"reference/api/query/#desi.query.conversation_engine.ChatbotEngine.call_rag_engine","title":"<code>call_rag_engine(state)</code>","text":"<p>Node that queries the RAG engine, providing history and query separately.</p>"},{"location":"reference/api/query/#desi.query.conversation_engine.ChatbotEngine.update_memory","title":"<code>update_memory(state)</code>","text":"<p>Node that saves the latest user query and assistant response to memory.</p>"},{"location":"reference/api/query/#desi.query.conversation_engine.ChatbotEngine.chat","title":"<code>chat(user_input, session_id)</code>","text":"<p>Processes a single user message through the LangGraph workflow.</p>"},{"location":"reference/api/query/#desi.query.conversation_engine.ChatbotEngine.start_chat_session","title":"<code>start_chat_session()</code>","text":"<p>Starts an interactive chat session in the terminal.</p>"},{"location":"reference/api/scraper/","title":"Scraper API","text":""},{"location":"reference/api/scraper/#desi.scraper.openbis_scraper.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/scraper/#desi.scraper.openbis_scraper.BASE_URL","title":"<code>BASE_URL = 'https://openbis.readthedocs.io/en/20.10.0-11/'</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/scraper/#desi.scraper.openbis_scraper.OUTPUT_DIRECTORY","title":"<code>OUTPUT_DIRECTORY = './data/raw/openbis/improved'</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/scraper/#desi.scraper.openbis_scraper.scraper","title":"<code>scraper = OpenbisScraper(BASE_URL, OUTPUT_DIRECTORY)</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/scraper/#desi.scraper.openbis_scraper.OpenbisScraper","title":"<code>OpenbisScraper</code>","text":"<p>Crawls a readthedocs site, converts the main content of each page to Markdown, and saves it to .md files.</p>"},{"location":"reference/api/scraper/#desi.scraper.openbis_scraper.OpenbisScraper.base_url","title":"<code>base_url = base_url</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/scraper/#desi.scraper.openbis_scraper.OpenbisScraper.output_dir","title":"<code>output_dir = output_dir</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/scraper/#desi.scraper.openbis_scraper.OpenbisScraper.to_visit","title":"<code>to_visit = initial_urls if initial_urls is not None else {base_url}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/scraper/#desi.scraper.openbis_scraper.OpenbisScraper.visited","title":"<code>visited = set()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/scraper/#desi.scraper.openbis_scraper.OpenbisScraper.max_pages","title":"<code>max_pages = max_pages</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/scraper/#desi.scraper.openbis_scraper.OpenbisScraper.__init__","title":"<code>__init__(base_url, output_dir, initial_urls=None, max_pages=None)</code>","text":"<p>Initializes the scraper with the target URL and output directory.</p> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>str</code> <p>The starting URL of the documentation site.</p> required <code>output_dir</code> <code>str</code> <p>The directory where Markdown files will be saved.</p> required <code>initial_urls</code> <code>set</code> <p>A set of initial URLs to crawl.                           Defaults to the base_url.</p> <code>None</code> <code>max_pages</code> <code>int</code> <p>A safety limit on the number of pages to scrape.</p> <code>None</code>"},{"location":"reference/api/scraper/#desi.scraper.openbis_scraper.OpenbisScraper.scrape","title":"<code>scrape()</code>","text":"<p>Starts the crawling and scraping process.</p>"},{"location":"reference/api/utils/","title":"Utils API","text":"<p>Configuration management for DeSi.</p> <p>This module provides centralized configuration management with support for environment variables and .env files.</p> <p>Logging utilities for DeSi Helper.</p>"},{"location":"reference/api/utils/#desi.utils.config.DOTENV_AVAILABLE","title":"<code>DOTENV_AVAILABLE = True</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/utils/#desi.utils.config.DesiConfig","title":"<code>DesiConfig</code>","text":"<p>Centralized configuration for DeSi.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.db_path","title":"<code>db_path</code>  <code>property</code>","text":"<p>Path to ChromaDB database directory.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.collection_name","title":"<code>collection_name</code>  <code>property</code>","text":"<p>ChromaDB collection name.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.memory_db_path","title":"<code>memory_db_path</code>  <code>property</code>","text":"<p>Path to SQLite conversation memory database.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.model_name","title":"<code>model_name</code>  <code>property</code>","text":"<p>Ollama model name for chat.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.embedding_model_name","title":"<code>embedding_model_name</code>  <code>property</code>","text":"<p>Ollama model name for embeddings.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.data_dir","title":"<code>data_dir</code>  <code>property</code>","text":"<p>Data directory path.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.processed_data_dir","title":"<code>processed_data_dir</code>  <code>property</code>","text":"<p>Processed data directory path.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.openbis_url","title":"<code>openbis_url</code>  <code>property</code>","text":"<p>OpenBIS ReadTheDocs URL.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.wikijs_url","title":"<code>wikijs_url</code>  <code>property</code>","text":"<p>Wiki.js DataStore URL.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.max_pages_per_scraper","title":"<code>max_pages_per_scraper</code>  <code>property</code>","text":"<p>Maximum pages per scraper (None for unlimited).</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.min_chunk_size","title":"<code>min_chunk_size</code>  <code>property</code>","text":"<p>Minimum chunk size in characters.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.max_chunk_size","title":"<code>max_chunk_size</code>  <code>property</code>","text":"<p>Maximum chunk size in characters.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.chunk_overlap","title":"<code>chunk_overlap</code>  <code>property</code>","text":"<p>Chunk overlap in characters.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.retrieval_top_k","title":"<code>retrieval_top_k</code>  <code>property</code>","text":"<p>Number of chunks to retrieve for RAG.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.history_limit","title":"<code>history_limit</code>  <code>property</code>","text":"<p>Number of conversation turns to keep in memory.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.web_host","title":"<code>web_host</code>  <code>property</code>","text":"<p>Web interface host.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.web_port","title":"<code>web_port</code>  <code>property</code>","text":"<p>Web interface port.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.web_debug","title":"<code>web_debug</code>  <code>property</code>","text":"<p>Enable web debug mode.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.secret_key","title":"<code>secret_key</code>  <code>property</code>","text":"<p>Flask secret key.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.cors_origins","title":"<code>cors_origins</code>  <code>property</code>","text":"<p>CORS allowed origins.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.log_level","title":"<code>log_level</code>  <code>property</code>","text":"<p>Logging level.</p>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.__init__","title":"<code>__init__(env_file=None)</code>","text":"<p>Initialize configuration.</p> <p>Parameters:</p> Name Type Description Default <code>env_file</code> <code>Optional[str]</code> <p>Path to .env file (optional)</p> <code>None</code>"},{"location":"reference/api/utils/#desi.utils.config.DesiConfig.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert configuration to dictionary.</p>"},{"location":"reference/api/utils/#desi.utils.logging.setup_logging","title":"<code>setup_logging(level=logging.INFO)</code>","text":"<p>Set up logging for the application.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <p>The logging level to use</p> <code>INFO</code>"},{"location":"reference/api/web/","title":"Web API","text":"<p>Web interface for DeSi using FastAPI and Gradio.</p> <p>This module provides a modern web interface for interacting with DeSi through a browser-based chat interface powered by Gradio, with a FastAPI backend for robust API handling.</p> <p>CLI launcher for DeSi web interface.</p> <p>This module provides a command-line interface to launch the DeSi web server using uvicorn with FastAPI and Gradio.</p>"},{"location":"reference/api/web/#desi.web.app.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/web/#desi.web.app.conversation_engine","title":"<code>conversation_engine = None</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/web/#desi.web.app.config","title":"<code>config = None</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/web/#desi.web.app.api_base_url","title":"<code>api_base_url = 'http://127.0.0.1:7860'</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/web/#desi.web.app.app","title":"<code>app = FastAPI(title='DeSi - DataStore Helper', description='RAG-focused chatbot for openBIS and DataStore documentation', version='2.0.0', lifespan=lifespan)</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/web/#desi.web.app.gradio_app","title":"<code>gradio_app = create_gradio_interface()</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/web/#desi.web.app.cfg","title":"<code>cfg = DesiConfig()</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/web/#desi.web.app.ChatRequest","title":"<code>ChatRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request model for chat endpoint.</p>"},{"location":"reference/api/web/#desi.web.app.ChatRequest.message","title":"<code>message</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/web/#desi.web.app.ChatRequest.session_id","title":"<code>session_id = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/api/web/#desi.web.app.ChatResponse","title":"<code>ChatResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response model for chat endpoint.</p>"},{"location":"reference/api/web/#desi.web.app.ChatResponse.response","title":"<code>response</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/web/#desi.web.app.ChatResponse.session_id","title":"<code>session_id</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/web/#desi.web.app.ChatResponse.sources","title":"<code>sources</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/web/#desi.web.app.ClearSessionRequest","title":"<code>ClearSessionRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request model for clearing session.</p>"},{"location":"reference/api/web/#desi.web.app.ClearSessionRequest.session_id","title":"<code>session_id</code>  <code>instance-attribute</code>","text":""},{"location":"reference/api/web/#desi.web.app.init_conversation_engine","title":"<code>init_conversation_engine()</code>","text":"<p>Initialize the conversation engine on application startup. This is called only once when the FastAPI server starts.</p>"},{"location":"reference/api/web/#desi.web.app.lifespan","title":"<code>lifespan(app)</code>  <code>async</code>","text":"<p>Lifespan context manager for FastAPI. Initializes the conversation engine on startup.</p>"},{"location":"reference/api/web/#desi.web.app.health_check","title":"<code>health_check()</code>  <code>async</code>","text":"<p>Health check endpoint.</p>"},{"location":"reference/api/web/#desi.web.app.chat_endpoint","title":"<code>chat_endpoint(request)</code>  <code>async</code>","text":"<p>Main chat endpoint for processing user messages.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>ChatRequest</code> <p>ChatRequest containing the user message and optional session_id</p> required <p>Returns:</p> Type Description <p>ChatResponse with the bot's response, session_id, and sources</p>"},{"location":"reference/api/web/#desi.web.app.clear_session_endpoint","title":"<code>clear_session_endpoint(request)</code>  <code>async</code>","text":"<p>Clear conversation memory for a specific session.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>ClearSessionRequest</code> <p>ClearSessionRequest containing the session_id</p> required <p>Returns:</p> Type Description <p>Success message</p>"},{"location":"reference/api/web/#desi.web.app.format_sources_display","title":"<code>format_sources_display(sources)</code>","text":"<p>Format sources for display in the Gradio interface.</p> <p>Parameters:</p> Name Type Description Default <code>sources</code> <code>List[dict]</code> <p>List of source dictionaries</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted string for display</p>"},{"location":"reference/api/web/#desi.web.app.chat_with_desi","title":"<code>chat_with_desi(message, history, session_id)</code>","text":"<p>Gradio chat function that communicates with the FastAPI backend.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>User's input message</p> required <code>history</code> <code>List[Tuple[str, str]]</code> <p>Current chat history (list of [user_msg, bot_msg] pairs)</p> required <code>session_id</code> <code>str</code> <p>Current session ID</p> required <p>Returns:</p> Type Description <code>Tuple[List[Tuple[str, str]], str]</code> <p>Tuple of (updated_history, session_id)</p>"},{"location":"reference/api/web/#desi.web.app.clear_conversation","title":"<code>clear_conversation(session_id)</code>","text":"<p>Clear the conversation history and start a new session.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str</code> <p>Current session ID</p> required <p>Returns:</p> Type Description <code>Tuple[List, str, str]</code> <p>Tuple of (empty_history, new_session_id, welcome_message)</p>"},{"location":"reference/api/web/#desi.web.app.create_gradio_interface","title":"<code>create_gradio_interface()</code>","text":"<p>Create and configure the Gradio chat interface.</p> <p>Returns:</p> Type Description <code>Blocks</code> <p>Configured Gradio Blocks interface</p>"},{"location":"reference/api/web/#desi.web.cli.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"reference/api/web/#desi.web.cli.main","title":"<code>main()</code>","text":"<p>Main entry point for the web interface CLI.</p>"},{"location":"tutorials/","title":"Tutorials","text":"<p>Hands-on guides that walk through running DeSi locally, preparing data, and issuing your first question. These tutorials assume you are working from the project root.</p> <ul> <li>Getting Started: install, prerequisites, and initial setup.</li> <li>Run Locally: what the workflow does on disk and how to rerun it safely.</li> <li>First Query: talk to the chatbot from the terminal and interpret sources.</li> </ul>"},{"location":"tutorials/first-query/","title":"First Query","text":"<p>Chat with DeSi from the terminal and read the cited sources.</p>"},{"location":"tutorials/first-query/#start-the-chatbot","title":"Start the Chatbot","text":"<p>You need a populated vector store in <code>desi_vectordb/</code> (run <code>python main.py</code> once to build it). Then start an interactive session: <pre><code>python -m desi.query.cli --db-path desi_vectordb --prompt-template prompts/desi_query_prompt.md\n</code></pre> If you prefer the end-to-end workflow, <code>python main.py</code> drops you into the same chat after scraping/processing when needed.</p>"},{"location":"tutorials/first-query/#ask-a-question","title":"Ask a Question","text":"<p>Sample prompts: - <code>How do I create a new experiment in openBIS?</code> - <code>Where do I find DataStore upload steps?</code></p> <p>The chatbot will: 1. Rewrite the question (LangGraph node) if conversation history exists. 2. Retrieve chunks from Chroma with a relevance threshold (default <code>0.7</code> in the CLI). 3. Generate an answer with the configured Ollama model.</p>"},{"location":"tutorials/first-query/#read-the-sources","title":"Read the Sources","text":"<p>After each response the CLI prints sources with origin labels (<code>dswiki</code> or <code>openbis</code>). Expect output similar to: <pre><code>Assistant: ...answer text...\n--- Sources Used ---\n- Origin: DataStore Wiki, Source: guides/upload.md\n- Origin: openBIS Wiki, Source: user_doc/experiments_create.md\n</code></pre></p> <p>If you see \u201cNo sources were used,\u201d the query did not pass the relevance threshold\u2014try a more specific question or rebuild embeddings with updated data.</p>"},{"location":"tutorials/getting-started/","title":"Getting Started","text":"<p>This walkthrough installs DeSi, checks prerequisites, and runs the full workflow once.</p>"},{"location":"tutorials/getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.8+ (project is tested with 3.10\u20133.12).</li> <li>Ollama running locally.</li> <li>Models: pull at least <code>nomic-embed-text</code> (embeddings) and a chat model (<code>gpt-oss:20b</code> is the code default; the README examples use <code>qwen3</code>). Set alternatives via <code>DESI_MODEL_NAME</code> and <code>DESI_EMBEDDING_MODEL_NAME</code>.</li> </ul>"},{"location":"tutorials/getting-started/#install","title":"Install","text":"<pre><code>python -m venv .venv\n. .venv/Scripts/activate        # Windows (PowerShell)\n# source .venv/bin/activate     # macOS/Linux\npip install -e \".[dev]\"\n</code></pre>"},{"location":"tutorials/getting-started/#initialize","title":"Initialize","text":"<p>Run the helper to create folders and copy <code>.env.example</code> to <code>.env</code> if missing: <pre><code>python init.py\n</code></pre> The script checks Ollama availability, creates <code>data/raw</code>, <code>data/processed</code>, and <code>desi_vectordb</code>, and verifies imports.</p>"},{"location":"tutorials/getting-started/#first-full-run","title":"First Full Run","text":"<p>Start the all-in-one pipeline (scrape \u2192 process \u2192 chat): <pre><code>python main.py\n</code></pre> What happens: 1. If <code>desi_vectordb/</code> is missing, the pipeline scrapes sources and processes them. 2. If raw data exists but no vector DB, only processing runs. 3. If both exist, it skips to the chat interface.</p> <p>Use <code>--force-scraping</code> or <code>--force-processing</code> to refresh data, or <code>--skip-*</code> flags to bypass stages. Add <code>--web</code> to launch the FastAPI/Gradio interface instead of the terminal chat.</p>"},{"location":"tutorials/run-locally/","title":"Run Locally","text":"<p>Learn what DeSi creates on disk and how to rerun the workflow safely.</p>"},{"location":"tutorials/run-locally/#directory-layout-after-setup","title":"Directory Layout After Setup","text":"<ul> <li><code>data/raw/openbis</code> and <code>data/raw/wikijs</code>: scraped Markdown.</li> <li><code>data/processed/openbis</code> and <code>data/processed/wikijs</code>: cleaned/chunked exports (CSV/JSON/JSONL).</li> <li><code>desi_vectordb/</code>: ChromaDB persistence (vector store used by the query engine).</li> <li><code>data/conversation_memory.db</code>: SQLite chat history used by LangGraph memory.</li> <li><code>prompts/desi_query_prompt.md</code>: prompt template loaded by the RAG engine.</li> </ul>"},{"location":"tutorials/run-locally/#typical-local-run","title":"Typical Local Run","text":"<pre><code># assumes venv is active\npython main.py\n</code></pre>"},{"location":"tutorials/run-locally/#control-the-workflow","title":"Control the Workflow","text":"<ul> <li><code>--skip-scraping</code> / <code>--skip-processing</code>: skip steps even if prerequisites are missing (will error if the next stage has no data).</li> <li><code>--force-scraping</code> / <code>--force-processing</code>: rerun stages even when outputs already exist (useful after changing chunking or models).</li> <li><code>--web</code>: start the FastAPI/Gradio UI instead of the terminal chat.</li> <li><code>--config &lt;file&gt;</code>: load alternate <code>.env</code> file; environment variables still override file values.</li> </ul>"},{"location":"tutorials/run-locally/#rerunning-safely","title":"Rerunning Safely","text":"<ul> <li>To rebuild the vector store from fresh data, delete or move <code>desi_vectordb/</code> and rerun <code>python main.py --force-scraping --force-processing</code>.</li> <li>To keep the current vector DB but refresh memory, delete <code>data/conversation_memory.db</code>.</li> <li>To inspect processed data before embedding, open the CSV/JSON files under <code>data/processed/**</code>.</li> </ul>"}]}